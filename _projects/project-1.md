---
title: Emergent Abilities in Language Reasoning Models at Test Time
layout: home
order: 1
---

Sharp, non-linear jumps in model performance have previously been observed when language model size and training compute are scaled [(Wei et al., 2022)](https://arxiv.org/abs/2206.07682), [(Berti et al., 2025)](https://arxiv.org/abs/2503.05788). This poses a challenge to forecasting model capabilities; ideally, all capabilities of interest would display smooth, continuous scaling. Additionally, recent work has identified test-time compute scaling laws [(Wu et al., 2025)](https://arxiv.org/abs/2408.00724), [(Snell et al., 2024)](https://arxiv.org/abs/2408.03314). This study investigates the presence of emergent scaling in language reasoning models at test-time.

[See an early draft of the work here](/assets/docs/summary_emergent_test_time_scaling.pdf)

[See an in-progress codebase here](https://github.com/IyngkarranKumar/test_time_emergent_scaling/tree/clean_public_branch)